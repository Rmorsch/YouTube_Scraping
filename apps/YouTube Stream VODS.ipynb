{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35a80a92d92fe2a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:16:40.106740Z",
     "start_time": "2025-07-05T00:16:40.096760Z"
    }
   },
   "outputs": [],
   "source": [
    "import os, sys, time, math, itertools, json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from googleapiclient.discovery import build\n",
    "from tqdm import tqdm   # progress bar\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus  # safely URL-encode the driver name\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "from googleapiclient.discovery import build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4363f0c04d5152d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:16:40.146351Z",
     "start_time": "2025-07-05T00:16:40.139770Z"
    }
   },
   "outputs": [],
   "source": [
    "API_KEY = os.getenv(\"YOUTUBE_API_KEY\")  \n",
    "if not API_KEY:\n",
    "    raise SystemExit(\"No YOUTUBE_API_KEY Found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f701925e7ec31e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:16:40.440671Z",
     "start_time": "2025-07-05T00:16:40.432569Z"
    }
   },
   "outputs": [],
   "source": [
    "def normalize_dataframe(df):\n",
    "    df[\"published_at\"] = (\n",
    "        pd.to_datetime(df[\"published_at\"], utc=True)  # parse ISO-8601\n",
    "          .dt.tz_convert(None)                       # drop the UTC tz-info\n",
    "    )\n",
    "\n",
    "    # --- make sure numeric cols are true ints, not NaN/float strings ----------\n",
    "    num_cols = [\"view_count\", \"like_count\", \"comment_count\", \"favorite_count\"]\n",
    "    df[num_cols] = (\n",
    "        df[num_cols]\n",
    "          .fillna(0)            # YouTube may omit like_count, etc. -> NaN\n",
    "          .astype(\"Int64\")      # pandas nullable int → SQL BIGINT/INT fine\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71b78371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build engine (same style you've been using)\n",
    "def select_all_azure_sql():\n",
    "    drv = \"ODBC Driver 18 for SQL Server\"\n",
    "    odbc_str = (\n",
    "        f\"DRIVER={{{drv}}};\"\n",
    "        f\"SERVER=tcp:{os.getenv('AZSQL_SERVER')},1433;\"\n",
    "        f\"DATABASE={os.getenv('AZSQL_DATABASE')};\"\n",
    "        f\"UID={os.getenv('AZSQL_USERNAME')};\"\n",
    "        f\"PWD={os.getenv('AZSQL_PASSWORD')};\"\n",
    "        \"Encrypt=yes;\"\n",
    "        \"TrustServerCertificate=no;\"\n",
    "        \"Connection Timeout=30;\"\n",
    "    )\n",
    "\n",
    "    params = quote_plus(odbc_str)\n",
    "    engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "    # read table into pandas\n",
    "    df = pd.read_sql(\"SELECT * FROM YOUTUBE_API.Vaush_VIDEOS\", engine)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e9aaa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_new_videos(df_in_database, df_from_api):\n",
    "    keys = set(df_in_database[\"video_id\"])\n",
    "    df_filtered = df_from_api[~df_from_api[\"video_id\"].isin(keys)]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "950754d9f4f70aad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:16:40.467131Z",
     "start_time": "2025-07-05T00:16:40.459036Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_to_azure_sql(df):\n",
    "    \"\"\"\n",
    "    Write/append the dataframe into dbo.youtube_videos (Azure SQL DB)\n",
    "    \"\"\"\n",
    "\n",
    "    drv = \"ODBC Driver 18 for SQL Server\"            # keep spaces!\n",
    "    odbc_str = (\n",
    "        f\"Driver={drv};Server=tcp:{os.getenv('AZSQL_SERVER')},1433;\"\n",
    "        f\"Database={os.getenv('AZSQL_DATABASE')};\"\n",
    "        f\"Uid={os.getenv('AZSQL_USERNAME')};\"\n",
    "        f\"Pwd={os.getenv('AZSQL_PASSWORD')};\"\n",
    "        \"Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
    "    )\n",
    "\n",
    "    # SQLAlchemy-style URL.  Space → + ;  parentheses → %28 %29, etc.\n",
    "    params = quote_plus(odbc_str)\n",
    "    engine = create_engine(\n",
    "        f\"mssql+pyodbc:///?odbc_connect={params}\",\n",
    "        fast_executemany=True        # batches rows under the hood\n",
    "    )\n",
    "\n",
    "    # —— upsert strategy: try append-only, let PK skip duplicates\n",
    "    with engine.begin() as cn:\n",
    "        df.to_sql(\n",
    "            name=\"Vaush_VIDEOS\",\n",
    "            con=cn,\n",
    "            schema=\"YOUTUBE_API\",\n",
    "            if_exists=\"append\",       # create once, then append\n",
    "            index=False,\n",
    "            chunksize=1000,           # good balance of  network / TX\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c35846aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# 1) Find playlist(s) by expected name\n",
    "# ----------------------------\n",
    "\n",
    "def find_playlists_by_name(\n",
    "    yt,\n",
    "    channel_id: str,\n",
    "    expected_names: List[str],\n",
    "    max_pages: int = 50,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Returns playlists whose title contains any of the expected name phrases (case-insensitive).\n",
    "    Example expected_names:\n",
    "      [\"stream vod\", \"stream archive\", \"past streams\", \"vods\", \"live vod\"]\n",
    "    \"\"\"\n",
    "    expected = [s.lower() for s in expected_names]\n",
    "    matches: List[Dict] = []\n",
    "\n",
    "    page_token: Optional[str] = None\n",
    "    pages = 0\n",
    "\n",
    "    while True:\n",
    "        resp = yt.playlists().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            channelId=channel_id,\n",
    "            maxResults=50,\n",
    "            pageToken=page_token,\n",
    "        ).execute()\n",
    "\n",
    "        for item in resp.get(\"items\", []):\n",
    "            title = (item.get(\"snippet\", {}) or {}).get(\"title\", \"\") or \"\"\n",
    "            title_l = title.lower()\n",
    "\n",
    "            if any(phrase in title_l for phrase in expected):\n",
    "                matches.append({\n",
    "                    \"playlist_id\": item[\"id\"],\n",
    "                    \"title\": title,\n",
    "                    \"item_count\": (item.get(\"contentDetails\", {}) or {}).get(\"itemCount\", 0),\n",
    "                })\n",
    "\n",
    "        page_token = resp.get(\"nextPageToken\")\n",
    "        pages += 1\n",
    "        if not page_token or pages >= max_pages:\n",
    "            break\n",
    "\n",
    "    return matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302e57a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 2) Iterate playlist videos and pull video metadata\n",
    "# ----------------------------\n",
    "\n",
    "def list_video_ids_in_playlist(yt, playlist_id: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns all videoIds in a playlist.\n",
    "    Note: playlist items can include \"Private video\"/\"Deleted video\" placeholders -> those will have no videoId.\n",
    "    \"\"\"\n",
    "    video_ids: List[str] = []\n",
    "    page_token: Optional[str] = None\n",
    "\n",
    "    while True:\n",
    "        resp = yt.playlistItems().list(\n",
    "            part=\"snippet\",\n",
    "            playlistId=playlist_id,\n",
    "            maxResults=50,\n",
    "            pageToken=page_token,\n",
    "        ).execute()\n",
    "\n",
    "        for item in resp.get(\"items\", []):\n",
    "            snip = item.get(\"snippet\", {}) or {}\n",
    "            resource = snip.get(\"resourceId\", {}) or {}\n",
    "            vid = resource.get(\"videoId\")\n",
    "            if vid:\n",
    "                video_ids.append(vid)\n",
    "\n",
    "        page_token = resp.get(\"nextPageToken\")\n",
    "        if not page_token:\n",
    "            break\n",
    "\n",
    "    # de-dup but keep stable order\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for v in video_ids:\n",
    "        if v not in seen:\n",
    "            seen.add(v)\n",
    "            out.append(v)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ab9e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fetch_videos(yt, video_ids: List[str]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch video metadata in batches of 50.\n",
    "    Includes liveStreamingDetails so you can detect completed livestreams.\n",
    "    \"\"\"\n",
    "    out: List[Dict] = []\n",
    "\n",
    "    for i in range(0, len(video_ids), 50):\n",
    "        batch = video_ids[i:i + 50]\n",
    "        resp = yt.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics,status,liveStreamingDetails\",\n",
    "            id=\",\".join(batch),\n",
    "        ).execute()\n",
    "\n",
    "        for v in resp.get(\"items\", []):\n",
    "            snip = v.get(\"snippet\", {}) or {}\n",
    "            cdet = v.get(\"contentDetails\", {}) or {}\n",
    "            stats = v.get(\"statistics\", {}) or {}\n",
    "            status = v.get(\"status\", {}) or {}\n",
    "            live = v.get(\"liveStreamingDetails\") or {}\n",
    "\n",
    "            out.append({\n",
    "                \"video_id\": v.get(\"id\"),\n",
    "                \"title\": snip.get(\"title\"),\n",
    "                \"published_at\": snip.get(\"publishedAt\"),\n",
    "                \"duration\": cdet.get(\"duration\"),\n",
    "                \"view_count\": int(stats[\"viewCount\"]) if \"viewCount\" in stats else None,\n",
    "                \"comment_count\": int(stats[\"commentCount\"]) if \"commentCount\" in stats else None,\n",
    "                \"like_count\": int(stats[\"likeCount\"]) if \"likeCount\" in stats else None,\n",
    "                \"privacy_status\": status.get(\"privacyStatus\"),\n",
    "                # livestream timestamps if it was a live broadcast (completed/upcoming/live)\n",
    "                \"live_actual_start\": live.get(\"actualStartTime\"),\n",
    "                \"live_actual_end\": live.get(\"actualEndTime\"),\n",
    "                \"live_scheduled_start\": live.get(\"scheduledStartTime\"),\n",
    "            })\n",
    "\n",
    "    return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "389b0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# Single entrypoint (minimal)\n",
    "# ----------------------------\n",
    "\n",
    "def get_stream_vod_videos_from_channel(\n",
    "    api_key: str,\n",
    "    channel_id: str,\n",
    "    expected_playlist_names: List[str],\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    1) Find playlist(s) whose name matches your expected patterns\n",
    "    2) Pull all videos from those playlists and return video metadata\n",
    "    \"\"\"\n",
    "    yt = build(\"youtube\", \"v3\", developerKey=api_key)\n",
    "\n",
    "    playlists = find_playlists_by_name(\n",
    "        yt=yt,\n",
    "        channel_id=channel_id,\n",
    "        expected_names=expected_playlist_names,\n",
    "    )\n",
    "\n",
    "    all_videos: List[Dict] = []\n",
    "    for pl in playlists:\n",
    "        vids = list_video_ids_in_playlist(yt, pl[\"playlist_id\"])\n",
    "        video_rows = fetch_videos(yt, vids)\n",
    "\n",
    "        # tag provenance\n",
    "        for row in video_rows:\n",
    "            row[\"discovery_playlist_id\"] = pl[\"playlist_id\"]\n",
    "            row[\"discovery_playlist_title\"] = pl[\"title\"]\n",
    "\n",
    "        all_videos.extend(video_rows)\n",
    "\n",
    "    # de-dup by video_id (video can appear in multiple playlists)\n",
    "    by_id = {}\n",
    "    for v in all_videos:\n",
    "        by_id.setdefault(v[\"video_id\"], v)\n",
    "\n",
    "    return {\n",
    "        \"channel_id\": channel_id,\n",
    "        \"matched_playlists\": playlists,\n",
    "        \"videos\": list(by_id.values()),\n",
    "        \"video_count\": len(by_id),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00909e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'playlist_id': 'PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw', 'title': 'Stream VODs', 'item_count': 1655}]\n",
      "1649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = get_stream_vod_videos_from_channel(\n",
    "        api_key=API_KEY,\n",
    "        channel_id=os.getenv('VAUSH_CHANNEL_ID'),\n",
    "        expected_playlist_names=[\"Stream VODs\"]\n",
    "        )\n",
    "    print(result[\"matched_playlists\"])\n",
    "    print(result[\"video_count\"])\n",
    "    df = pd.DataFrame(result[\"videos\"])\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7f613",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0d9a00bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1649 entries, 0 to 1648\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   video_id                  1649 non-null   object\n",
      " 1   title                     1649 non-null   object\n",
      " 2   published_at              1649 non-null   object\n",
      " 3   duration                  1649 non-null   object\n",
      " 4   view_count                1649 non-null   int64 \n",
      " 5   comment_count             1649 non-null   int64 \n",
      " 6   like_count                1649 non-null   int64 \n",
      " 7   privacy_status            1649 non-null   object\n",
      " 8   live_actual_start         1633 non-null   object\n",
      " 9   live_actual_end           1633 non-null   object\n",
      " 10  live_scheduled_start      1631 non-null   object\n",
      " 11  discovery_playlist_id     1649 non-null   object\n",
      " 12  discovery_playlist_title  1649 non-null   object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 167.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd81ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>published_at</th>\n",
       "      <th>duration</th>\n",
       "      <th>view_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>privacy_status</th>\n",
       "      <th>live_actual_start</th>\n",
       "      <th>live_actual_end</th>\n",
       "      <th>live_scheduled_start</th>\n",
       "      <th>discovery_playlist_id</th>\n",
       "      <th>discovery_playlist_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OgoXU9JeYvM</td>\n",
       "      <td>Farewell to the first year of the American Cen...</td>\n",
       "      <td>2025-12-30T21:05:00Z</td>\n",
       "      <td>PT3H36M10S</td>\n",
       "      <td>38978</td>\n",
       "      <td>16</td>\n",
       "      <td>2044</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2025-12-30T21:39:03Z</td>\n",
       "      <td>2025-12-31T01:15:09Z</td>\n",
       "      <td>2025-12-30T22:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xwVy4LogYaA</td>\n",
       "      <td>WHO ELSE BIG AND ROUND</td>\n",
       "      <td>2025-12-27T18:50:17Z</td>\n",
       "      <td>PT3H25M29S</td>\n",
       "      <td>62587</td>\n",
       "      <td>131</td>\n",
       "      <td>2076</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2025-12-27T19:36:18Z</td>\n",
       "      <td>2025-12-27T23:01:42Z</td>\n",
       "      <td>2025-12-27T20:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3FO8tsABZ7Q</td>\n",
       "      <td>DOJ DISCOVERS \"OVER ONE MILLION\" MORE EPSTEIN ...</td>\n",
       "      <td>2025-12-24T21:35:07Z</td>\n",
       "      <td>PT2H48M1S</td>\n",
       "      <td>63792</td>\n",
       "      <td>103</td>\n",
       "      <td>2143</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2025-12-24T21:41:48Z</td>\n",
       "      <td>2025-12-25T00:29:45Z</td>\n",
       "      <td>2025-12-24T22:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rRIFiKEsJi4</td>\n",
       "      <td>INSANE NEW EPSTEIN FILE DROP, TRUMP DIRECTLY I...</td>\n",
       "      <td>2025-12-23T23:25:38Z</td>\n",
       "      <td>PT2H3M42S</td>\n",
       "      <td>66713</td>\n",
       "      <td>110</td>\n",
       "      <td>2623</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2025-12-23T23:36:27Z</td>\n",
       "      <td>2025-12-24T01:40:03Z</td>\n",
       "      <td>2025-12-24T00:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kfa4zKe_jw8</td>\n",
       "      <td>EPSTEIN STORM BUILDS, BARI WEISS PULLS CBS REP...</td>\n",
       "      <td>2025-12-22T18:28:11Z</td>\n",
       "      <td>PT4H29M</td>\n",
       "      <td>84988</td>\n",
       "      <td>89</td>\n",
       "      <td>2651</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2025-12-22T19:40:44Z</td>\n",
       "      <td>2025-12-23T00:09:42Z</td>\n",
       "      <td>2025-12-22T20:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>Vn8zk7o9VOw</td>\n",
       "      <td>Yelling at Reactionary Videos - BraveTheWorld,...</td>\n",
       "      <td>2019-04-23T17:49:35Z</td>\n",
       "      <td>PT1M</td>\n",
       "      <td>3764</td>\n",
       "      <td>30</td>\n",
       "      <td>160</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2019-04-23T17:46:01Z</td>\n",
       "      <td>2019-04-23T17:46:57Z</td>\n",
       "      <td>2019-04-23T18:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>9rukHE7Hzf0</td>\n",
       "      <td>Discussing Racism</td>\n",
       "      <td>2019-04-23T01:41:09Z</td>\n",
       "      <td>PT3H9M57S</td>\n",
       "      <td>7558</td>\n",
       "      <td>30</td>\n",
       "      <td>279</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2019-04-22T22:00:38Z</td>\n",
       "      <td>2019-04-23T01:10:31Z</td>\n",
       "      <td>2019-04-22T22:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>Q7PWX39sCb0</td>\n",
       "      <td>This is a video game stream please do not come...</td>\n",
       "      <td>2019-04-22T06:26:32Z</td>\n",
       "      <td>PT2H13M7S</td>\n",
       "      <td>5163</td>\n",
       "      <td>12</td>\n",
       "      <td>143</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2019-04-22T04:01:29Z</td>\n",
       "      <td>2019-04-22T06:14:31Z</td>\n",
       "      <td>2019-04-22T04:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>hQc7QIsP_Yg</td>\n",
       "      <td>I love getting myself banned from streaming pl...</td>\n",
       "      <td>2019-04-18T20:22:47Z</td>\n",
       "      <td>PT51M27S</td>\n",
       "      <td>12153</td>\n",
       "      <td>70</td>\n",
       "      <td>475</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2019-04-18T18:56:48Z</td>\n",
       "      <td>2019-04-18T19:48:15Z</td>\n",
       "      <td>None</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>1TggpUmWqu0</td>\n",
       "      <td>FIRST YOUTUBE STREAM WOOOOOO</td>\n",
       "      <td>2019-04-18T19:13:17Z</td>\n",
       "      <td>PT2H56M29S</td>\n",
       "      <td>23749</td>\n",
       "      <td>116</td>\n",
       "      <td>736</td>\n",
       "      <td>unlisted</td>\n",
       "      <td>2019-04-18T15:58:16Z</td>\n",
       "      <td>2019-04-18T18:54:33Z</td>\n",
       "      <td>2019-04-18T16:00:00Z</td>\n",
       "      <td>PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw</td>\n",
       "      <td>Stream VODs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1649 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                              title  \\\n",
       "0     OgoXU9JeYvM  Farewell to the first year of the American Cen...   \n",
       "1     xwVy4LogYaA                             WHO ELSE BIG AND ROUND   \n",
       "2     3FO8tsABZ7Q  DOJ DISCOVERS \"OVER ONE MILLION\" MORE EPSTEIN ...   \n",
       "3     rRIFiKEsJi4  INSANE NEW EPSTEIN FILE DROP, TRUMP DIRECTLY I...   \n",
       "4     kfa4zKe_jw8  EPSTEIN STORM BUILDS, BARI WEISS PULLS CBS REP...   \n",
       "...           ...                                                ...   \n",
       "1644  Vn8zk7o9VOw  Yelling at Reactionary Videos - BraveTheWorld,...   \n",
       "1645  9rukHE7Hzf0                                  Discussing Racism   \n",
       "1646  Q7PWX39sCb0  This is a video game stream please do not come...   \n",
       "1647  hQc7QIsP_Yg  I love getting myself banned from streaming pl...   \n",
       "1648  1TggpUmWqu0                       FIRST YOUTUBE STREAM WOOOOOO   \n",
       "\n",
       "              published_at    duration  view_count  comment_count  like_count  \\\n",
       "0     2025-12-30T21:05:00Z  PT3H36M10S       38978             16        2044   \n",
       "1     2025-12-27T18:50:17Z  PT3H25M29S       62587            131        2076   \n",
       "2     2025-12-24T21:35:07Z   PT2H48M1S       63792            103        2143   \n",
       "3     2025-12-23T23:25:38Z   PT2H3M42S       66713            110        2623   \n",
       "4     2025-12-22T18:28:11Z     PT4H29M       84988             89        2651   \n",
       "...                    ...         ...         ...            ...         ...   \n",
       "1644  2019-04-23T17:49:35Z        PT1M        3764             30         160   \n",
       "1645  2019-04-23T01:41:09Z   PT3H9M57S        7558             30         279   \n",
       "1646  2019-04-22T06:26:32Z   PT2H13M7S        5163             12         143   \n",
       "1647  2019-04-18T20:22:47Z    PT51M27S       12153             70         475   \n",
       "1648  2019-04-18T19:13:17Z  PT2H56M29S       23749            116         736   \n",
       "\n",
       "     privacy_status     live_actual_start       live_actual_end  \\\n",
       "0          unlisted  2025-12-30T21:39:03Z  2025-12-31T01:15:09Z   \n",
       "1          unlisted  2025-12-27T19:36:18Z  2025-12-27T23:01:42Z   \n",
       "2          unlisted  2025-12-24T21:41:48Z  2025-12-25T00:29:45Z   \n",
       "3          unlisted  2025-12-23T23:36:27Z  2025-12-24T01:40:03Z   \n",
       "4          unlisted  2025-12-22T19:40:44Z  2025-12-23T00:09:42Z   \n",
       "...             ...                   ...                   ...   \n",
       "1644       unlisted  2019-04-23T17:46:01Z  2019-04-23T17:46:57Z   \n",
       "1645       unlisted  2019-04-22T22:00:38Z  2019-04-23T01:10:31Z   \n",
       "1646       unlisted  2019-04-22T04:01:29Z  2019-04-22T06:14:31Z   \n",
       "1647       unlisted  2019-04-18T18:56:48Z  2019-04-18T19:48:15Z   \n",
       "1648       unlisted  2019-04-18T15:58:16Z  2019-04-18T18:54:33Z   \n",
       "\n",
       "      live_scheduled_start               discovery_playlist_id  \\\n",
       "0     2025-12-30T22:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "1     2025-12-27T20:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "2     2025-12-24T22:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "3     2025-12-24T00:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "4     2025-12-22T20:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "...                    ...                                 ...   \n",
       "1644  2019-04-23T18:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "1645  2019-04-22T22:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "1646  2019-04-22T04:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "1647                  None  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "1648  2019-04-18T16:00:00Z  PLvVEXejrE-HT5SPUUMaZ1QcTxa2S3PvPw   \n",
       "\n",
       "     discovery_playlist_title  \n",
       "0                 Stream VODs  \n",
       "1                 Stream VODs  \n",
       "2                 Stream VODs  \n",
       "3                 Stream VODs  \n",
       "4                 Stream VODs  \n",
       "...                       ...  \n",
       "1644              Stream VODs  \n",
       "1645              Stream VODs  \n",
       "1646              Stream VODs  \n",
       "1647              Stream VODs  \n",
       "1648              Stream VODs  \n",
       "\n",
       "[1649 rows x 13 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed4f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ec9fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(df):\n",
    "    # --- Parse Youtube datetimes ----------  \n",
    "    dt_cols = [\n",
    "        \"published_at\",\n",
    "        \"live_actual_start\",\n",
    "        \"live_actual_end\",\n",
    "        \"live_scheduled_start\",\n",
    "    ]\n",
    "\n",
    "    df[dt_cols] = df[dt_cols].apply(\n",
    "        pd.to_datetime,\n",
    "        utc=True,\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    # --- make sure numeric cols are true ints, not NaN/float strings ----------\n",
    "    num_cols = [\"view_count\", \"like_count\", \"comment_count\"]\n",
    "    df[num_cols] = (\n",
    "        df[num_cols]\n",
    "        .fillna(0)            # YouTube may omit like_count, etc. -> NaN\n",
    "        .astype(\"Int64\")      # pandas nullable int → SQL BIGINT/INT fine\n",
    "    )\n",
    "\n",
    "    # --- Uppercase columns names ----------\n",
    "    df.columns = [col.upper() for col in df.columns]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "00eac5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd7f195f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1649 entries, 0 to 1648\n",
      "Data columns (total 13 columns):\n",
      " #   Column                    Non-Null Count  Dtype              \n",
      "---  ------                    --------------  -----              \n",
      " 0   VIDEO_ID                  1649 non-null   object             \n",
      " 1   TITLE                     1649 non-null   object             \n",
      " 2   PUBLISHED_AT              1649 non-null   datetime64[ns, UTC]\n",
      " 3   DURATION                  1649 non-null   object             \n",
      " 4   VIEW_COUNT                1649 non-null   Int64              \n",
      " 5   COMMENT_COUNT             1649 non-null   Int64              \n",
      " 6   LIKE_COUNT                1649 non-null   Int64              \n",
      " 7   PRIVACY_STATUS            1649 non-null   object             \n",
      " 8   LIVE_ACTUAL_START         1633 non-null   datetime64[ns, UTC]\n",
      " 9   LIVE_ACTUAL_END           1633 non-null   datetime64[ns, UTC]\n",
      " 10  LIVE_SCHEDULED_START      1631 non-null   datetime64[ns, UTC]\n",
      " 11  DISCOVERY_PLAYLIST_ID     1649 non-null   object             \n",
      " 12  DISCOVERY_PLAYLIST_TITLE  1649 non-null   object             \n",
      "dtypes: Int64(3), datetime64[ns, UTC](4), object(6)\n",
      "memory usage: 172.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359bceb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary ~: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df[\u001b[43m~\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDiscovery_Playlist_Title\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m]\n",
      "\u001b[31mTypeError\u001b[39m: bad operand type for unary ~: 'list'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae7619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
